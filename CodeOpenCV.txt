import cv2
import mediapipe as mp
import serial
import time

# Initialiser la communication série avec l'Arduino
arduino = serial.Serial('COM3', 9600)  # Remplacer 'COM3' par votre port
time.sleep(2)  # Attendre la connexion

# Initialiser MediaPipe pour la détection des mains
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)
mp_draw = mp.solutions.drawing_utils

# Ouvrir la caméra
cap = cv2.VideoCapture(0)

# Seuils pour déterminer si un doigt est plié
FINGER_CLOSED_THRESHOLD = 0.03

def is_finger_closed(finger_tip, finger_dip, finger_pip):
    # Calculer la distance entre l'extrémité du doigt et la base
    distance = abs(finger_tip.y - finger_pip.y)
    return distance < FINGER_CLOSED_THRESHOLD

while True:
    ret, frame = cap.read()
    if not ret:
        break
        
    # Convertir l'image en RGB
    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    image.flags.writeable = False
    
    # Détection des mains
    results = hands.process(image)
    
    # Réinitialiser les états des doigts
    finger_states = [0, 0, 0, 0, 0]  # [Pouce, Index, Majeur, Annulaire, Auriculaire]
    
    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            # Récupérer les points de repère pour chaque doigt
            landmarks = hand_landmarks.landmark
            
            # Détection pour chaque doigt
            # Pouce
            thumb_state = is_finger_closed(landmarks[4], landmarks[3], landmarks[2])
            # Index
            index_state = is_finger_closed(landmarks[8], landmarks[7], landmarks[6])
            # Majeur
            middle_state = is_finger_closed(landmarks[12], landmarks[11], landmarks[10])
            # Annulaire
            ring_state = is_finger_closed(landmarks[16], landmarks[15], landmarks[14])
            # Auriculaire
            pinky_state = is_finger_closed(landmarks[20], landmarks[19], landmarks[18])
            
            finger_states = [
                1 if thumb_state else 0,
                1 if index_state else 0,
                1 if middle_state else 0,
                1 if ring_state else 0,
                1 if pinky_state else 0
            ]
            
            # Dessiner les points de repère sur l'image
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
    
    # Envoyer les états des doigts à l'Arduino
    command = f"${finger_states[0]}{finger_states[1]}{finger_states[2]}{finger_states[3]}{finger_states[4]}"
    arduino.write(command.encode())
    
    # Afficher les états des doigts sur l'image
    cv2.putText(frame, f"Pouce: {finger_states[0]}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    cv2.putText(frame, f"Index: {finger_states[1]}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    cv2.putText(frame, f"Majeur: {finger_states[2]}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    cv2.putText(frame, f"Annulaire: {finger_states[3]}", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    cv2.putText(frame, f"Auriculaire: {finger_states[4]}", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    # Afficher l'image
    cv2.imshow('Hand Tracking', frame)
    
    # Quitter avec la touche 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Nettoyage
cap.release()
cv2.destroyAllWindows()
arduino.close()